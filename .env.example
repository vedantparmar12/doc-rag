# ============================================
# MCP DOCS RAG - ENVIRONMENT CONFIGURATION
# ============================================

# ----------------
# REQUIRED SETTINGS
# ----------------

# Path to your documentation folder
DOCS_FOLDER=C:/path/to/your/team/docs

# ----------------
# EMBEDDING PROVIDER (Choose one)
# ----------------

# Option 1: LOCAL HUGGINGFACE (RECOMMENDED - FREE!)
# No API key needed, runs locally
EMBEDDING_PROVIDER=local
EMBEDDING_MODEL=all-MiniLM-L6-v2  # Fast, 384-dim
# EMBEDDING_MODEL=all-mpnet-base-v2  # Better quality, 768-dim
# EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2  # Multilingual

# Option 2: HUGGINGFACE API (Has free tier)
# Get key from: https://huggingface.co/settings/tokens
# EMBEDDING_PROVIDER=huggingface
# HF_API_KEY=hf_your_key_here
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Option 3: OPENAI (Costs money)
# Get key from: https://platform.openai.com/api-keys
# EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=sk-your-key-here
# EMBEDDING_MODEL=text-embedding-3-small

# ----------------
# SEARCH CONFIGURATION
# ----------------

# Enable semantic search (requires embeddings)
ENABLE_SEMANTIC_SEARCH=true

# Enable reranking for better result quality (recommended!)
# Uses cross-encoder to rerank top candidates
# FREE - runs locally with HuggingFace models
ENABLE_RERANKING=true
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Enable image understanding with Docling VLM (slower but free)
ENABLE_IMAGE_UNDERSTANDING=false

# Maximum search results to return
MAX_RESULTS=10

# Advanced chunking options
CHUNK_MAX_TOKENS=512
CHUNK_WITH_HEADINGS=true
CHUNK_MERGE_PEERS=true

# ----------------
# LLM FOR SUMMARIZATION (Optional)
# ----------------

# If using GitHub Copilot in VS Code, you DON'T need this!
# Copilot will use the search results automatically.

# Only needed if you want the MCP server to do summarization:
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your-key-here
# LLM_MODEL=gpt-4o-mini

# ----------------
# ADVANCED FEATURES (NEW!)
# ----------------

# INCREMENTAL INDEXING - Only reindex changed files
ENABLE_INCREMENTAL_INDEXING=true
AUTO_UPDATE_ON_STARTUP=true

# HYBRID CHUNKER - Better document chunking
ENABLE_HYBRID_CHUNKER=true
CHUNK_MAX_TOKENS=512
CHUNK_OVERLAP_TOKENS=50
CHUNK_RESPECT_STRUCTURE=true

# QUERY DECOMPOSITION - Break complex queries
ENABLE_QUERY_DECOMPOSITION=true

# FEEDBACK SYSTEM - Learn from corrections
ENABLE_FEEDBACK_SYSTEM=true
REINDEX_THRESHOLD=10  # Reindex after N corrections

# CONVERSATION CONTEXT - Remember previous queries
ENABLE_CONVERSATION_CONTEXT=true
MAX_CONVERSATION_HISTORY=10
SESSION_TIMEOUT_HOURS=24

# ----------------
# PERFORMANCE TUNING
# ----------------

# Index storage path
INDEX_PATH=.index

# Search timeout (seconds)
SEARCH_TIMEOUT=30

# Maximum file size to process (MB)
MAX_FILE_SIZE_MB=10

# Chunk size for indexing
CHUNK_SIZE=1000

# Parallel processing workers
MAX_WORKERS=auto  # or specific number like 8

# Batch size for processing
BATCH_SIZE=10

# ----------------
# LOGGING
# ----------------

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
